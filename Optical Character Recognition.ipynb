{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9acc72fc",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [20]\u001b[0m, in \u001b[0;36m<cell line: 14>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;66;03m# Calculate the dominant angle of the lines\u001b[39;00m\n\u001b[0;32m    103\u001b[0m angles \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m--> 104\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m lines:\n\u001b[0;32m    105\u001b[0m    \u001b[38;5;28;01mfor\u001b[39;00m rho,theta \u001b[38;5;129;01min\u001b[39;00m line:\n\u001b[0;32m    106\u001b[0m      angle \u001b[38;5;241m=\u001b[39m theta \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m180\u001b[39m\u001b[38;5;241m/\u001b[39mnp\u001b[38;5;241m.\u001b[39mpi\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "                        #### Algorithm \n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import pytesseract\n",
    "import random\n",
    "from PIL import Image\n",
    "\n",
    "# Specify the path of the folder containing the images\n",
    "path = r\"M:\\OCR\\data3\"\n",
    "        \n",
    "image_files = [f for f in os.listdir(path) if f.endswith('.jpeg') or f.endswith('.png') or f.endswith('.jpg')]\n",
    "\n",
    "if image_files:\n",
    "    random_file = random.choice(image_files)\n",
    "    img = cv2.imread(os.path.join(path, random_file))\n",
    "       # Convert to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "       # Threshold the image\n",
    "    _, thresh = cv2.threshold(gray, 0, 250, cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)\n",
    "       #print(thresh[100])\n",
    "\n",
    "       # Find contours in the image\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        \n",
    "                             #### Algorithm 1-------Handwriting Recognition\n",
    "                                            ##text extraction\n",
    "       \n",
    "        # Filter to remove the noise\n",
    "    blur = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "\n",
    "        # Apply thresholding\n",
    "    thresh1 = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "\n",
    "        # Apply dilation and erosion\n",
    "    kernel = np.ones((1, 1), np.uint8)\n",
    "    dilate = cv2.dilate(thresh1, kernel, iterations=1)\n",
    "    erode = cv2.erode(dilate, kernel, iterations=1)\n",
    "\n",
    "        # Perform OCR using pytesseract\n",
    "    config = '--psm 11' # PSM 11 specifies that the image contains a single block of text of uniform size\n",
    "    text = pytesseract.image_to_string(erode,config=config)\n",
    "    #print(f\"Extracted text: {text}\")\n",
    "    \n",
    "    with open(r'M:\\OCR\\Report.txt', 'w') as file:    ##specify the path where you want to save the report/output file\n",
    "    # Write output to file\n",
    "       file.write(\"Extracted Text:\\n\")\n",
    "       file.write(text)\n",
    "      \n",
    "\n",
    "     \n",
    "            #### Algorithm -------Analysis of parameters and metrics\n",
    "                            ###slope of text\n",
    "\n",
    "       #Sort the contours from left to right based on their x-coordinates\n",
    "       sorted_contours = sorted(contours, key=lambda c: cv2.boundingRect(c)[0])\n",
    "\n",
    "       # Calculate the y-coordinate of the bottom  of the first two bounding boxes and then avg\n",
    "       x1, y1, w1, h1 = cv2.boundingRect(sorted_contours[0])\n",
    "       bottom_y1 = y1 + h1\n",
    "\n",
    "       if len(sorted_contours)>1:\n",
    "        x2, y2, w2, h2 = cv2.boundingRect(sorted_contours[1])\n",
    "        bottom_y2 = y2 + h2\n",
    "       else:\n",
    "        bottom_y2=bottom_y1\n",
    "    \n",
    "       avg1=(bottom_y1+bottom_y2)/2\n",
    "    \n",
    "       # Calculate the y-coordinate of the bottom  of the last two bounding boxes and then avg   \n",
    "       x4, y4, w4, h4 = cv2.boundingRect(sorted_contours[-1])\n",
    "       bottom_y4 = y4 + h4\n",
    "    \n",
    "       if len(sorted_contours)>1:\n",
    "        x3, y3, w3, h3 = cv2.boundingRect(sorted_contours[-2])\n",
    "        bottom_y3 = y3 + h3\n",
    "       else:\n",
    "        bottom_y3=bottom_y4\n",
    "    \n",
    "       avg2=(bottom_y3+bottom_y4)/2\n",
    "\n",
    "       # Calculate the difference between the y-coordinates of the bottom left and bottom right corners\n",
    "       slope = avg1 - avg2\n",
    "       #print(slope)\n",
    "    \n",
    "       file.write(\"Report:\\n\")\n",
    "    \n",
    "       if slope > 20:\n",
    "          file.write(\"1) Slope of the text indicates positivity, optimism and hope in the person's behaviour.\\n\")\n",
    "       elif slope < -7:\n",
    "          file.write(\"1) Slope of the text indicates feelings of sadness, disappointment and negativity in the person's behaviour.\\n\")\n",
    "       else:\n",
    "          file.write(\"1) Slope of the text indicates that the person is rational.\\n\")\n",
    "\n",
    "    \n",
    "                            #### Angle of writing\n",
    "\n",
    "       # Apply Hough transform to detect lines\n",
    "       lines = cv2.HoughLines(thresh, 1, np.pi/180, 50, min_theta=np.pi/4, max_theta=3*np.pi/4)\n",
    " \n",
    "       # Calculate the dominant angle of the lines\n",
    "       angles = []\n",
    "       for line in lines:\n",
    "          for rho,theta in line:\n",
    "            angle = theta * 180/np.pi\n",
    "            angles.append(angle)\n",
    "        \n",
    "       angles = np.asarray(angles)\n",
    "       median_angle = np.median(angles)\n",
    "       #print(\"Dominant angle:\", median_angle)\n",
    "\n",
    "       if median_angle > 93:\n",
    "            file.write('2) Handwriting that leans to the left indicates a restrained and closed person, who tries to be private, to '\\\n",
    "           'control his emotions and finds it difficult to be free and liberated.\\n')\n",
    "       elif median_angle < 87:\n",
    "            file.write('2) Handwriting that leans to the right indicates a very sociable person who is rational but also very '\\\n",
    "           'sensitive and warm.\\n')\n",
    "       else:\n",
    "          file.write(\"2) Straight handwriting indicates that the person is rational.\\n\")\n",
    "    \n",
    "                                ##thickness of handwriting\n",
    "\n",
    "        # Iterate over contours and find thickness of each contour\n",
    "       total_area = 0\n",
    "       width = img.shape[1]\n",
    "\n",
    "       for contour in contours:\n",
    "        total_area += cv2.contourArea(contour)\n",
    "\n",
    "      # Calculate thickness by dividing total area by image width\n",
    "       thickness = total_area / width\n",
    "      #print(\"Overall text thickness: \", thickness)\n",
    "\n",
    "       if thickness > 30:\n",
    "        file.write('3) Thick handwriting indicates a strong person with a strong and prominent personality, '\\\n",
    "          'who is good with commitments and takes things seriously.\\n')\n",
    "       else:\n",
    "        file.write('3) Thin Handwriting indicates a person who is more sensitive and passive.\\n')\n",
    "    \n",
    "    \n",
    "                          ##connected handwriting\n",
    "\n",
    "       # Apply morphological closing to connect nearby strokes\n",
    "       kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3,3))\n",
    "       dilated = cv2.dilate(thresh1, kernel, iterations=2)\n",
    "       closed = cv2.morphologyEx(dilated, cv2.MORPH_CLOSE, kernel, iterations=2)\n",
    "\n",
    "       contours, hierarchy = cv2.findContours(closed, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "       num_cc=0\n",
    "       for cnt in contours:\n",
    "         area = cv2.contourArea(cnt)\n",
    "         if area>100:\n",
    "          num_cc=num_cc+1\n",
    "        \n",
    "        ###calculate number of letters\n",
    "\n",
    "      # Count the number of alphabets in the extracted text\n",
    "       num_letters = 0\n",
    "       for char in text:\n",
    "        if char.isalpha():\n",
    "         num_letters += 1\n",
    "       #print(num_letters)\n",
    "    \n",
    "        # Calculate connectivity ratio      \n",
    "       if num_letters > 1:\n",
    "         connectivity_ratio = num_cc / num_letters\n",
    "       else:\n",
    "         connectivity_ratio = 0\n",
    "\n",
    "     # Print result\n",
    "      # print(\"Connectivity ratio: \", connectivity_ratio)\n",
    "\n",
    "       if connectivity_ratio < 0.5 and connectivity_ratio > 0 :     ##you can change it according to your dataset\n",
    "          file.write('4) Connected handwriting indicates a person who has good emotional expression, creativity, open minded artistry, a '\\\n",
    "       'strong desire for self expression and a tendency to be more spontaneous, and less organized. \\n')\n",
    "       else:\n",
    "          file.write('4) Writing which is not connected indicates an organized, efficient and practical person, with a strong ability '\\\n",
    "       'to focus on details.\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
